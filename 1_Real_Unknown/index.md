# 1_Real_Unknown âœ¨ â€” The \"Why\"

## ğŸ¯ Problem Definition
Efficiently set up **Crush CLI** (Charmbracelet's AI coding assistant) across **Windows** and **macOS** environments, including local AI stack with **Ollama** and **Qdrant** for offline capabilities.

## ğŸ“Š OKRs
- [ ] Crush CLI installed and functional on macOS (brew/winget)
- [ ] Crush CLI installed and functional on Windows (winget/scoop/WSL)
- [ ] Configured with remote APIs (OpenAI/Anthropic) and local Ollama
- [ ] Qdrant vector DB running locally for RAG/embeddings
- [ ] End-to-end test: Use Crush to edit code in this repo
- [ ] Documentation verified across environments

## â“ Core Questions
- What are the exact install commands for each OS?
- How to configure multiple providers (remote + local Ollama)?
- Docker compose for Ollama + Qdrant + nomic-embed-text?
- Common pitfalls on Windows (terminal, paths)?
- Integration with VSCode/LSP?

## ğŸ“ˆ Success Metrics
- Zero-downtime setup &lt; 30min per OS
- 100% feature parity (code editing, tools, autonomy)

**Status:** Defining the journey from unknown to proven. ğŸš€